{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "from keras.layers import LSTM, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
       "       [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
       "       [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
       "       [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
       "       [792, 'France', 'Female', ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
       "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 0, 0, ..., 1, 1, 101348.88],\n",
       "       [608, 2, 0, ..., 0, 1, 112542.58],\n",
       "       [502, 0, 0, ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [709, 0, 0, ..., 0, 1, 42085.58],\n",
       "       [772, 1, 1, ..., 1, 0, 92888.52],\n",
       "       [792, 0, 0, ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer with dropout\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dropout(0.25))\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.4398 - accuracy: 0.8077\n",
      "Epoch 2/150\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3920 - accuracy: 0.83 - 9s 11ms/step - loss: 0.3918 - accuracy: 0.8369\n",
      "Epoch 3/150\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.3724 - accuracy: 0.8478\n",
      "Epoch 4/150\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.3670 - accuracy: 0.8486\n",
      "Epoch 5/150\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.3612 - accuracy: 0.8496\n",
      "Epoch 6/150\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.3595 - accuracy: 0.85012s - loss: 0.3554 - accuracy - E - ETA: 1s - loss: 0.3593 - accuracy: 0.85 - ETA: 1s - loss: - ETA: 0s - loss: 0.3589  - ETA: 0s - loss: 0.3595 - accuracy: 0.\n",
      "Epoch 7/150\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.3577 - accuracy: 0.8522\n",
      "Epoch 8/150\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.3544 - accuracy: 0.8543\n",
      "Epoch 9/150\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.3555 - accuracy: 0.85212s - loss: 0.3502 - accuracy - ETA: 1s\n",
      "Epoch 10/150\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.3534 - accuracy: 0.85568s - loss: 0.3404 - accu - ETA: 8s - los - ETA: 5s - ETA: 4s - l - E - ETA: 1s - l - ETA: 0s - los\n",
      "Epoch 11/150\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.3520 - accuracy: 0.85441s - loss: 0.3485 - accuracy: 0.85 - ETA: 1s - loss: 0.3481 - accuracy - ETA: 0s - los - ETA: 0s - loss: 0.3521 - accuracy: 0.85\n",
      "Epoch 12/150\n",
      "800/800 [==============================] - 9s 12ms/step - loss: 0.3503 - accuracy: 0.8561 3s - loss: 0.357 -\n",
      "Epoch 13/150\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.3461 - accuracy: 0.8580\n",
      "Epoch 14/150\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.3501 - accuracy: 0.8546\n",
      "Epoch 15/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.3474 - accuracy: 0.8591\n",
      "Epoch 16/150\n",
      "800/800 [==============================] - 12s 16ms/step - loss: 0.3485 - accuracy: 0.8571\n",
      "Epoch 17/150\n",
      "800/800 [==============================] - 14s 18ms/step - loss: 0.3434 - accuracy: 0.85990s - loss: 0.3428 - accuracy: 0. - ETA: 0s - loss: 0.3432 - accura\n",
      "Epoch 18/150\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 0.3414 - accuracy: 0.85771s - loss: - ETA: \n",
      "Epoch 19/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.3417 - accuracy: 0.8599\n",
      "Epoch 20/150\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.3428 - accuracy: 0.8595\n",
      "Epoch 21/150\n",
      "800/800 [==============================] - 8s 9ms/step - loss: 0.3401 - accuracy: 0.8601\n",
      "Epoch 22/150\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.3416 - accuracy: 0.8611\n",
      "Epoch 23/150\n",
      "800/800 [==============================] - 8s 11ms/step - loss: 0.3414 - accuracy: 0.8624\n",
      "Epoch 24/150\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.3414 - accuracy: 0.8602\n",
      "Epoch 25/150\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.3389 - accuracy: 0.8599ETA: 0s - loss: 0.3 - ETA: 0s - loss: 0.3396 - accura\n",
      "Epoch 26/150\n",
      "800/800 [==============================] - 9s 12ms/step - loss: 0.3400 - accuracy: 0.8596 0s - loss: 0.3419 - accuracy: 0. - ETA: 0s -\n",
      "Epoch 27/150\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.3397 - accuracy: 0.8612: 17s - loss: 0.3501 - accuracy: 0. - ETA: 17s - loss: 0.3414  - ETA: 17s - \n",
      "Epoch 28/150\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.3355 - accuracy: 0.8621\n",
      "Epoch 29/150\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.3372 - accuracy: 0.8637: 0s - loss: 0.3371 - accuracy\n",
      "Epoch 30/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3368 - accuracy: 0.8589\n",
      "Epoch 31/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3359 - accuracy: 0.8649\n",
      "Epoch 32/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3354 - accuracy: 0.8615\n",
      "Epoch 33/150\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3376 - accuracy: 0.8602\n",
      "Epoch 34/150\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3352 - accuracy: 0.8639\n",
      "Epoch 35/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.3338 - accuracy: 0.8627\n",
      "Epoch 36/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3345 - accuracy: 0.8639\n",
      "Epoch 37/150\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3329 - accuracy: 0.8631\n",
      "Epoch 38/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3344 - accuracy: 0.8616\n",
      "Epoch 39/150\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3346 - accuracy: 0.8639\n",
      "Epoch 40/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.3321 - accuracy: 0.8622\n",
      "Epoch 41/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.3345 - accuracy: 0.8597\n",
      "Epoch 42/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3329 - accuracy: 0.8625\n",
      "Epoch 43/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3337 - accuracy: 0.8646\n",
      "Epoch 44/150\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.3323 - accuracy: 0.8649\n",
      "Epoch 45/150\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3342 - accuracy: 0.8627\n",
      "Epoch 46/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3357 - accuracy: 0.8652\n",
      "Epoch 47/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.3326 - accuracy: 0.8648: 0s - loss: 0.3301 \n",
      "Epoch 48/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3298 - accuracy: 0.8661TA: 0s - loss: 0.3280 - accuracy\n",
      "Epoch 49/150\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.3320 - accuracy: 0.8645\n",
      "Epoch 50/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.3346 - accuracy: 0.8646: 0s - loss: 0.3\n",
      "Epoch 51/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.3301 - accuracy: 0.8627\n",
      "Epoch 52/150\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.3319 - accuracy: 0.8641\n",
      "Epoch 53/150\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.3329 - accuracy: 0.8619\n",
      "Epoch 54/150\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.3297 - accuracy: 0.8684\n",
      "Epoch 55/150\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.3305 - accuracy: 0.8641 ETA: 5s - loss: 0.332 - ETA - ETA: 4s - loss: 0.3284 - accuracy: 0. - ETA: 4s - l - ETA: 3s - l\n",
      "Epoch 56/150\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.3300 - accuracy: 0.86559s - - ETA: 7s - loss: 0.3365 - accuracy - ETA: 7s - ETA: 0s - loss: 0.3315 - accuracy:  - ETA: 0s - loss: 0.3319 - \n",
      "Epoch 57/150\n",
      "800/800 [==============================] - 9s 12ms/step - loss: 0.3298 - accuracy: 0.8640\n",
      "Epoch 58/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.3299 - accuracy: 0.8668: 1s - loss: 0.3292  - ETA: 0s - loss: - ETA: 0s - loss: 0.3306  - ETA: 0s - loss: 0.3310 - accu\n",
      "Epoch 59/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3347 - accuracy: 0.8654TA: 12s - loss: 0.3327 -\n",
      "Epoch 60/150\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3343 - accuracy: 0.8639\n",
      "Epoch 61/150\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3312 - accuracy: 0.8664\n",
      "Epoch 62/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3303 - accuracy: 0.8659\n",
      "Epoch 63/150\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.3309 - accuracy: 0.8629ETA: 3s - loss: 0.3323  - ETA: 3s - loss: 0.3344 - accuracy - ETA: 3s - - ETA: 2s - loss: 0.3346 - accuracy: 0. - ETA: 2s - loss: - ETA: 0s - l\n",
      "Epoch 64/150\n",
      "800/800 [==============================] - 9s 12ms/step - loss: 0.3318 - accuracy: 0.8649 1s - loss: 0.3336 - accura - ETA: 1s - loss: 0.3335 - accuracy: 0.86 - ETA: 1s - loss: 0.3333 - accuracy - ETA: 1s - ETA: 1s - loss: 0.3\n",
      "Epoch 65/150\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3323 - accuracy: 0.8651\n",
      "Epoch 66/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 2s 2ms/step - loss: 0.3311 - accuracy: 0.8669\n",
      "Epoch 67/150\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3298 - accuracy: 0.8644\n",
      "Epoch 68/150\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3305 - accuracy: 0.8634\n",
      "Epoch 69/150\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.3300 - accuracy: 0.8652\n",
      "Epoch 70/150\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3264 - accuracy: 0.8671\n",
      "Epoch 71/150\n",
      "800/800 [==============================] - 3s 4ms/step - loss: 0.3304 - accuracy: 0.8637: 0s - loss: 0.3304 - accuracy: 0.\n",
      "Epoch 72/150\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3321 - accuracy: 0.8644\n",
      "Epoch 73/150\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.3271 - accuracy: 0.8652\n",
      "Epoch 74/150\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.3311 - accuracy: 0.8655: 0s - loss:\n",
      "Epoch 75/150\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3296 - accuracy: 0.8629\n",
      "Epoch 76/150\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3260 - accuracy: 0.8676: 0s - loss:\n",
      "Epoch 77/150\n",
      "800/800 [==============================] - 3s 4ms/step - loss: 0.3264 - accuracy: 0.8645\n",
      "Epoch 78/150\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.3271 - accuracy: 0.8643: 3s - loss: 0.3453 \n",
      "Epoch 79/150\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.3267 - accuracy: 0.8679\n",
      "Epoch 80/150\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3327 - accuracy: 0.8635\n",
      "Epoch 81/150\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.3297 - accuracy: 0.8665\n",
      "Epoch 82/150\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.3306 - accuracy: 0.8633\n",
      "Epoch 83/150\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3283 - accuracy: 0.8655\n",
      "Epoch 84/150\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.3261 - accuracy: 0.8655\n",
      "Epoch 85/150\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.3281 - accuracy: 0.8640: 0s - loss: 0.329\n",
      "Epoch 86/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3286 - accuracy: 0.8654\n",
      "Epoch 87/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3303 - accuracy: 0.8660\n",
      "Epoch 88/150\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3298 - accuracy: 0.8640\n",
      "Epoch 89/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3264 - accuracy: 0.8658\n",
      "Epoch 90/150\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.3270 - accuracy: 0.8696\n",
      "Epoch 91/150\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3266 - accuracy: 0.8636\n",
      "Epoch 92/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3263 - accuracy: 0.8656\n",
      "Epoch 93/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3270 - accuracy: 0.8637\n",
      "Epoch 94/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3287 - accuracy: 0.8643\n",
      "Epoch 95/150\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3270 - accuracy: 0.8634\n",
      "Epoch 96/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3272 - accuracy: 0.8669\n",
      "Epoch 97/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3250 - accuracy: 0.8674\n",
      "Epoch 98/150\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.3280 - accuracy: 0.8643\n",
      "Epoch 99/150\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3270 - accuracy: 0.86 - 4s 5ms/step - loss: 0.3266 - accuracy: 0.8661\n",
      "Epoch 100/150\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3268 - accuracy: 0.8685\n",
      "Epoch 101/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3281 - accuracy: 0.8658: 0s - loss: 0\n",
      "Epoch 102/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3259 - accuracy: 0.8671\n",
      "Epoch 103/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.3246 - accuracy: 0.8661\n",
      "Epoch 104/150\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3268 - accuracy: 0.8652\n",
      "Epoch 105/150\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3272 - accuracy: 0.8658\n",
      "Epoch 106/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3277 - accuracy: 0.8660: 1s\n",
      "Epoch 107/150\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3253 - accuracy: 0.8677\n",
      "Epoch 108/150\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3269 - accuracy: 0.8662\n",
      "Epoch 109/150\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3254 - accuracy: 0.8660\n",
      "Epoch 110/150\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3250 - accuracy: 0.8677\n",
      "Epoch 111/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3251 - accuracy: 0.8679: 0s - loss: 0.3\n",
      "Epoch 112/150\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3224 - accuracy: 0.8664\n",
      "Epoch 113/150\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.3272 - accuracy: 0.8679\n",
      "Epoch 114/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3264 - accuracy: 0.8686: 0s - loss: 0.323\n",
      "Epoch 115/150\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3271 - accuracy: 0.8654: 1s - loss: - - ETA: 0s - loss: 0.3258 \n",
      "Epoch 116/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3256 - accuracy: 0.8679\n",
      "Epoch 117/150\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3261 - accuracy: 0.8670\n",
      "Epoch 118/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3262 - accuracy: 0.8646: 1s - los - ETA: 0s - loss: 0.3249 - accura\n",
      "Epoch 119/150\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3245 - accuracy: 0.86 - 5s 7ms/step - loss: 0.3242 - accuracy: 0.8655\n",
      "Epoch 120/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3282 - accuracy: 0.8660: 0s - loss: 0.3277 - ac\n",
      "Epoch 121/150\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3265 - accuracy: 0.8654: 0s - l\n",
      "Epoch 122/150\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3247 - accuracy: 0.8681: 0s - l\n",
      "Epoch 123/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3274 - accuracy: 0.8643\n",
      "Epoch 124/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3262 - accuracy: 0.8677: 0s - loss: 0.3276 \n",
      "Epoch 125/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3234 - accuracy: 0.8649\n",
      "Epoch 126/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3256 - accuracy: 0.8684\n",
      "Epoch 127/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3236 - accuracy: 0.8676\n",
      "Epoch 128/150\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3273 - accuracy: 0.8644: 1s - loss: 0.3216 \n",
      "Epoch 129/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3241 - accuracy: 0.8665\n",
      "Epoch 130/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3244 - accuracy: 0.8674: 3s\n",
      "Epoch 131/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3286 - accuracy: 0.8648: 2s - loss: 0.3286 - accuracy: 0.86 - ETA\n",
      "Epoch 132/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3245 - accuracy: 0.8670\n",
      "Epoch 133/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3267 - accuracy: 0.8661\n",
      "Epoch 134/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3239 - accuracy: 0.8648\n",
      "Epoch 135/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3217 - accuracy: 0.8679: 0s - loss:\n",
      "Epoch 136/150\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3238 - accuracy: 0.8680: 0s - loss:\n",
      "Epoch 137/150\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.3253 - accuracy: 0.8689\n",
      "Epoch 138/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.3225 - accuracy: 0.8684\n",
      "Epoch 139/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.3234 - accuracy: 0.8675: 1s - loss: 0.321\n",
      "Epoch 140/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3264 - accuracy: 0.8676\n",
      "Epoch 141/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3266 - accuracy: 0.8664: 1s - loss: 0.3260 - accuracy: 0.\n",
      "Epoch 142/150\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.3244 - accuracy: 0.8700\n",
      "Epoch 143/150\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3258 - accuracy: 0.8654\n",
      "Epoch 144/150\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3220 - accuracy: 0.8695\n",
      "Epoch 145/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3228 - accuracy: 0.8706\n",
      "Epoch 146/150\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3233 - accuracy: 0.8686: 0s - loss: 0.3232 - accuracy: 0.86 - ETA: 0s - loss: 0.3229 - accuracy\n",
      "Epoch 147/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3244 - accuracy: 0.8677\n",
      "Epoch 148/150\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.3224 - accuracy: 0.8684: 0s - loss: 0.3252 - ac\n",
      "Epoch 149/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3249 - accuracy: 0.8622\n",
      "Epoch 150/150\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3233 - accuracy: 0.8711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x3245e280>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size=10, epochs=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 87.66%\n",
      "\n",
      "[[1524   71]\n",
      " [ 199  206]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "# Results - Accuracy\n",
    "y_pred=classifier.predict(X_test)\n",
    "y_pred=np.argmax(y_pred, axis=1)\n",
    "accuracy_score(y_test,y_pred)\n",
    "#plt.plot( classifier.history.epoch, classifier.history.history['loss'])\n",
    "#plt.xlabel('epochs')\n",
    "#plt.xlabel('loss')\n",
    "#plt.show()\n",
    "#plt.clf()\n",
    "\n",
    "scores1 = classifier.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: %.2f%%\\n\" % (scores1[1]*100))\n",
    "\n",
    "# Results - Confusion Matrix\n",
    "y_test_pred = classifier.predict_classes(X_test)\n",
    "c_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "print(c_matrix)\n",
    "ax = sns.heatmap(c_matrix, annot=True, xticklabels=['No exit', 'exit'], yticklabels=['No Exit', 'exit'], cbar=False, cmap='Blues')\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "plt.show()\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting a single new observation\n",
    "\"\"\"Predict if the customer with the following informations will leave the bank:\n",
    "Geography: France\n",
    "Credit Score: 600\n",
    "Gender: Male\n",
    "Age: 40\n",
    "Tenure: 3\n",
    "Balance: 60000\n",
    "Number of Products: 2\n",
    "Has Credit Card: Yes\n",
    "Is Active Member: Yes\n",
    "Estimated Salary: 50000\"\"\"\n",
    "new_prediction = classifier.predict(sc.transform(np.array([[0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])))\n",
    "new_prediction = (new_prediction > 0.5)\n",
    "\n",
    "print(new_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
